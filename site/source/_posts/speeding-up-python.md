---
title: Speeding up python programs with Numba
date: 2018-09-23 16:21:56
tags:
- python
- development
- performance
---

## When Python is not enough
The Python programming language is a great tool for almost any kind of rapid prototyping and quick development. It has great features such as its high level nature, a syntax with almost human-level readability . Besides, it is cross platform, with a a diverse standard library and it is multi-paradigm, giving a lot of freedom to the programmer which can use different programming paradigms such as [object-oriented](https://en.wikipedia.org/wiki/Object-oriented_programming), [functional](https://en.wikipedia.org/wiki/Functional_programming) or [procedural](https://en.wikipedia.org/wiki/Procedural_programming) as he sees fit. However, sometimes some portion of our system has high performance requirements and thus the speed that Python offers might not be sufficient. So, how can we boost performance without leaving the realm of Python (using for example compiled languages such as C/C++ or JIT/compiled such as JAVA) and when all of our optimizations are not enough anymore ? 

A possible solution is to make use of Numba, a runtime compiler that translates Python code to native instructions, while letting us use the concise and expressiveness power of Python and also achieve native code speed.

## Whats is Numba ?

[Numba](https://numba.pydata.org/) is a library that performs [JIT](https://en.wikipedia.org/wiki/Just-in-time_compilation) compilation, that is, translates pure python code to optimized machine code at runtime, using the [LLVM](https://llvm.org/) industry-standard compiler. It is also able to automatically parallelize loops and run them on multiple cores. Numba is cross-platform since it works on different operative systems (Linux, Windows, OSX) and different architectures (x86, x86_64, ppc64le, etc). It is also able to run the same code on a GPU (NVIDIA CUDA or AMD ROC) and is compatible with Python 2.7 and 3.4-3.7. Overall, the most impressive feature is its simplicity of use since we only need a few decorators to leverage the full power of JIT optimizations.

## Numba modes and the @jit decorator

The most important instruction is the *@jit* decorator. It is this decorator that instructs the compiler which mode to run and with what configurations . Under the hood, the generated bytecode of our decorated functions combined with the arguments that we specify in the decorator, such as the type of the input arguments, are analysed, optimized and finally compiled with the LLVM, generating specially tailored native machine instructions for the CPU currently in use. This compiled version is then reused for each function call.

There are two important modes: *nopython* and *object*. The *nopython* completely avoids the python interpreter and translates the full code to native instructions that can be run without the help of Python . However, if for some reason, that mode is not available (for example, when using unsupported Python features or external libraries) the compilation will fall back to the *object* mode, where it uses the Python interpreter when it is unable to compile some code . Naturally, the *nopython* mode is the one who offers the best performance gains.


## Speeding numerical computations: An example

The best use case where we can make use of the Numba library is when we have to do intensive numerical computations. As an example, let's compute the softmax function on a set of 2^16 (65536) random numbers. The softmax function, useful to convert a set of real values into probabilities and commonly used as the last layer in neural networks architectures, is defined as:


$$ \sigma(z_j) = { e^{z_j}  \over \sum_{k=1}^{K}  e^{z_k} } $$

A possible implementation of this function is as follows:

```bash
import time
import numpy as np
from numba import jit


@jit("f8[:](f8[:])", nopython=True, nogil=True, parallel=True)
def softmax(z):
    s = np.empty(z.shape)
    for j in range(z.shape[0]):
        s[j] = np.exp(z[j]) / np.sum(np.exp(z))
    return s


def main():
    np.random.seed(0)
    z = np.random.rand(2 ** 16)

    start = time.time()
    s = softmax(z)
    elapsed = time.time() - start

    print(s, '\nRan softmax calculations in {} seconds'.format(elapsed))


if __name__ == '__main__':
    main()
```

In the code above, there is already the Numba annotation that 


```bash
[1.53983982e-05 1.81857688e-05 1.62519575e-05 ... 1.66401328e-05
 9.79635582e-06 2.06871411e-05] 
Ran softmax calculations in 16.70321774482727 seconds
```

```bash
[1.53983982e-05 1.81857688e-05 1.62519575e-05 ... 1.66401328e-05
 9.79635582e-06 2.06871411e-05] 
Ran softmax calculations in 55.84803915023804 seconds

```