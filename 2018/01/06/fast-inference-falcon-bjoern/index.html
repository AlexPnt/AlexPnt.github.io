<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="A good portion of time in building supervised machine learning models is spent into training, that is, finding the best set of parameters that will give us the best accuracies on unseen data. Once we">
<meta name="keywords" content="python,performance,machine-learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Building a fast inference service with falcon and bjoern">
<meta property="og:url" content="https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/index.html">
<meta property="og:site_name" content="Alexandre Pinto">
<meta property="og:description" content="A good portion of time in building supervised machine learning models is spent into training, that is, finding the best set of parameters that will give us the best accuracies on unseen data. Once we">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://alexpnt.github.io/images/falcon-bjoern/falcon-bjoern-latency.png">
<meta property="og:image" content="https://alexpnt.github.io/images/falcon-bjoern/bjoern-gunicorn.png">
<meta property="og:updated_time" content="2020-08-22T15:04:57.159Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Building a fast inference service with falcon and bjoern">
<meta name="twitter:description" content="A good portion of time in building supervised machine learning models is spent into training, that is, finding the best set of parameters that will give us the best accuracies on unseen data. Once we">
<meta name="twitter:image" content="https://alexpnt.github.io/images/falcon-bjoern/falcon-bjoern-latency.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Building a fast inference service with falcon and bjoern</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- rss --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
</head>

<body>
    
      <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="header-post">
  <a id="menu-icon" href="#"><i class="fa fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fa fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/cv/">CV</a></li>
         
          <li><a href="/blog/">Blog</a></li>
         
          <li><a href="/papers/">Papers</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2018/01/27/nvidia-cuda-for-deep-learning/"><i class="fa fa-chevron-left" aria-hidden="true" onmouseover='$("#i-prev").toggle();' onmouseout='$("#i-prev").toggle();'></i></a></li>
        
        
        <li><a class="icon" href="/2017/09/10/ml-pipeline-6/"><i class="fa fa-chevron-right" aria-hidden="true" onmouseover='$("#i-next").toggle();' onmouseout='$("#i-next").toggle();'></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa fa-chevron-up" aria-hidden="true" onmouseover='$("#i-top").toggle();' onmouseout='$("#i-top").toggle();'></i></a></li>
        <li><a class="icon" href="#"><i class="fa fa-share-alt" aria-hidden="true" onmouseover='$("#i-share").toggle();' onmouseout='$("#i-share").toggle();' onclick='$("#share").toggle();return false;'></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/"><i class="fa fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&text=Building a fast inference service with falcon and bjoern"><i class="fa fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&is_video=false&description=Building a fast inference service with falcon and bjoern"><i class="fa fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Building a fast inference service with falcon and bjoern&body=Check out this article: https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/"><i class="fa fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&name=Building a fast inference service with falcon and bjoern&description="><i class="fa fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#installing-dependencies"><span class="toc-number">1.</span> <span class="toc-text">Installing dependencies</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#download-the-pre-trained-model"><span class="toc-number">2.</span> <span class="toc-text">Download the pre-trained model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#creating-a-rest-resource"><span class="toc-number">3.</span> <span class="toc-text">Creating a REST resource</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#making-queries"><span class="toc-number">4.</span> <span class="toc-text">Making queries</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#how-does-it-scale"><span class="toc-number">5.</span> <span class="toc-text">How does it scale ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#final-remarks"><span class="toc-number">6.</span> <span class="toc-text">Final remarks</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index width mx-auto px2 my4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Building a fast inference service with falcon and bjoern
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Alexandre Pinto</span>
      </span>
      
    <div class="postdate">
        <time datetime="2018-01-06T16:25:16.000Z" itemprop="datePublished">2018-01-06</time>
    </div>


      
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/machine-learning/">machine-learning</a>, <a class="tag-link" href="/tags/performance/">performance</a>, <a class="tag-link" href="/tags/python/">python</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>A good portion of time in building supervised machine learning models is spent into training, that is, finding the best set of parameters that will give us the best accuracies on unseen data. Once we are satisfied with the obtained results, we often need to deploy and make it available to answer queries from a wide range of sources.</p>
<p>We can elaborate complex scenarios that are able to scale and answer to thousands of requests. However, let us consider that we need to prototype and showcase a quick solution, without sacrificing performance and scalability.</p>
<p>For this scenario we can combine the <a href="https://falconframework.org" target="_blank" rel="noopener">Falcon</a> framework, which is a highly optimized and reliable web framework with <a href="https://github.com/jonashaag/bjoern" target="_blank" rel="noopener">bjoern</a>, a very lightweight and fast WSGI server. This post shows a possible use of these tools. For the inference model, we will use a pre-trained model built with the <a href="https://fasttext.cc" target="_blank" rel="noopener">fasttext</a> classification tool. This model is able to classify text according to its polarity.</p>
<h2 id="installing-dependencies">Installing dependencies</h2>
<ul>
<li>Optional virtual environment</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtualenv -p python3 venv</span><br></pre></td></tr></table></figure>
<ul>
<li>Falcon and Bjoern</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install ujson</span><br><span class="line">pip install cython</span><br><span class="line">pip install --no-binary :all: falcon </span><br><span class="line">pip install bjoern</span><br></pre></td></tr></table></figure>
<ul>
<li>FastText</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/facebookresearch/fastText.git</span><br><span class="line">cd fastText</span><br><span class="line">pip install pybind11</span><br><span class="line">python setup.py install</span><br><span class="line">cd ..</span><br></pre></td></tr></table></figure>
<h2 id="download-the-pre-trained-model">Download the pre-trained model</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir models</span><br><span class="line">wget --directory-prefix=models https://s3-us-west-1.amazonaws.com/fasttext-vectors/supervised_models/amazon_review_full.ftz</span><br></pre></td></tr></table></figure>
<h2 id="creating-a-rest-resource">Creating a REST resource</h2>
<p>In order to serve requests by answering with polarity predictions (number of stars), let's define a resource by specifying a REST endpoint.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> fastText</span><br><span class="line"><span class="keyword">import</span> falcon</span><br><span class="line"><span class="keyword">import</span> bjoern</span><br><span class="line"><span class="keyword">import</span> ujson</span><br><span class="line"></span><br><span class="line">REVIEW_MODEL = <span class="string">'models/amazon_review_full.ftz'</span></span><br><span class="line">WEB_HOST = <span class="string">'127.0.0.1'</span></span><br><span class="line">PORT = <span class="number">9000</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Loading amazon review polarity model ...'</span>)</span><br><span class="line">review_classifier = fastText.load_model(REVIEW_MODEL)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReviewResource</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">on_post</span><span class="params">(self, req, resp)</span>:</span></span><br><span class="line">		form = req.params</span><br><span class="line">		<span class="keyword">if</span> <span class="string">'text'</span> <span class="keyword">in</span> form <span class="keyword">and</span> form[<span class="string">'text'</span>]:</span><br><span class="line">			<span class="keyword">try</span>:</span><br><span class="line">				classification, confidence = review_classifier.predict(form[<span class="string">'text'</span>])</span><br><span class="line">				resp.body = ujson.dumps(&#123;<span class="string">'&#123;&#125; star'</span>.format(classification[<span class="number">0</span>][<span class="number">-1</span>]) : confidence[<span class="number">0</span>]&#125;)</span><br><span class="line">				resp.status = falcon.HTTP_200</span><br><span class="line">			<span class="keyword">except</span>:</span><br><span class="line">				resp.body = ujson.dumps(&#123;<span class="string">'Error'</span>: <span class="string">'An internal server error has occurred'</span>&#125;)</span><br><span class="line">				resp.status = falcon.HTTP_500</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">		    resp.body = ujson.dumps(&#123;<span class="string">'Error'</span>: <span class="string">'param \'text\' is mandatory'</span>&#125;)</span><br><span class="line">		    resp.status = falcon.HTTP_400</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># instantiate a callable WSGI app</span></span><br><span class="line">app = falcon.API()</span><br><span class="line"></span><br><span class="line"><span class="comment"># long-lived resource class instance</span></span><br><span class="line">infer_review = ReviewResource()</span><br><span class="line"></span><br><span class="line"><span class="comment"># handle all requests to the '/inferreview' URL path</span></span><br><span class="line">app.req_options.auto_parse_form_urlencoded = <span class="keyword">True</span></span><br><span class="line">app.add_route(<span class="string">'/inferreview'</span>, infer_review)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Listening on'</span>, WEB_HOST + <span class="string">':'</span> + str(PORT) + <span class="string">'/inferreview'</span>)</span><br><span class="line">bjoern.run(app, WEB_HOST, PORT, reuse_port=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>In the above code, we define an handler for POST requests, instantiate the application, configure routing and finally run the bjoern WSGI server.</p>
<h2 id="making-queries">Making queries</h2>
<p>The command bellow allow us to make queries to our web server. As an example, the request asks for a rating of the following review: 'I love this product.'</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://localhost:9000/inferreview -H &apos;Content-Type: application/x-www-form-urlencoded&apos; -d text=&quot;I love this product.&quot;</span><br></pre></td></tr></table></figure>
<p>which gives the desired classification, along with its confidence:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"5 star"</span>: <span class="number">0.7544972301</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="how-does-it-scale">How does it scale ?</h2>
<p>We have a server answering to client queries. We can make a quick test in order assess the scalability of our system. The <a href="https://github.com/giltene/wrk2" target="_blank" rel="noopener">wrk2</a> tool is perfect for this since it allows to record the latency distribution for different throughput (request per second) values.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/giltene/wrk2.git</span><br><span class="line">cd wrk2</span><br><span class="line">make</span><br><span class="line">./wrk -t4 -c400 -d30s -R25000 -L -s scripts/post.lua http://127.0.0.1:9000/inferreview</span><br></pre></td></tr></table></figure>
<p>The above command tests our server using 4 client threads, keeping 400 connections open, during 30 seconds and with a constant throughput of 20000 per second. The file scripts/post.lua is also modified as follows:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wrk.method = &quot;POST&quot;</span><br><span class="line">wrk.body   = &quot;text=&apos;awesome product&apos;&quot;</span><br><span class="line">wrk.headers[&quot;Content-Type&quot;] = &quot;application/x-www-form-urlencoded&quot;</span><br><span class="line">wrk.headers[&quot;Cache-Control&quot;] = &quot;no-cache&quot;</span><br></pre></td></tr></table></figure>
<p>The wrk2 tool generates a large output, containing a complete report with statistics in the <a href="https://github.com/HdrHistogram/HdrHistogram" target="_blank" rel="noopener">HdrHistogram</a> (High Dynamic Range Histogram) format, which we can use to make a plot of different throughput rates, as shown in the figure bellow:</p>
<p><img src="/images/falcon-bjoern/falcon-bjoern-latency.png"></p>
<p>We can see the server handles 99% of all requests under 60 milliseconds, even when the throughput is 20000 requests per second, which is a fairly good performance. As a further comparison, the plot bellow shows a comparison with the popular wsgi server <a href="http://gunicorn.org" target="_blank" rel="noopener">gunicorn</a>, with the same constant throughput rate.</p>
<p><img src="/images/falcon-bjoern/bjoern-gunicorn.png"></p>
<p>The gunicorn server ran with 9 asynchronous worker processes, based on <a href="http://www.gevent.org" target="_blank" rel="noopener">gevent</a> threads and it was called with the following command:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gunicorn polarity_server:app -w 9 -k gevent</span><br></pre></td></tr></table></figure>
<p>It is clear that the bjoern server handled requests faster than gunicorn, and thus is a strong and faster alternative. These tests were performed on a standard laptop with 4 cores.</p>
<h2 id="final-remarks">Final remarks</h2>
<p>Falcon and Bjoern make a great combination to quickly serve thousands of requests with low effort and also make a good starting point for more complex scenarios. This speedup is justified since Falcon itself was compiled with <a href="http://cython.org" target="_blank" rel="noopener">Cython</a>. We could have used the <a href="http://pypy.org" target="_blank" rel="noopener">pypy</a> python implementation alternative for even faster results. On the other hand, Bjoern is a very lightweight wsgi server, with a very low memory footprint, and single-threaded, which avoids locking overheads such as the <a href="https://wiki.python.org/moin/GlobalInterpreterLock" target="_blank" rel="noopener">GIL</a>. The right combination of tools, allow us to worry less on performance issues and focus more on implementing the task that we want to provide. Finally, the source code is available <a href="https://github.com/AlexPnt/falcon-polarity-inference" target="_blank" rel="noopener">here</a>.</p>

  </div>
</article>

    <div class="blog-post-comments">
        <div id="disqus_thread">
            <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        </div>
    </div>



    </div>
    
      <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/cv/">CV</a></li>
         
          <li><a href="/blog/">Blog</a></li>
         
          <li><a href="/papers/">Papers</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#installing-dependencies"><span class="toc-number">1.</span> <span class="toc-text">Installing dependencies</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#download-the-pre-trained-model"><span class="toc-number">2.</span> <span class="toc-text">Download the pre-trained model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#creating-a-rest-resource"><span class="toc-number">3.</span> <span class="toc-text">Creating a REST resource</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#making-queries"><span class="toc-number">4.</span> <span class="toc-text">Making queries</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#how-does-it-scale"><span class="toc-number">5.</span> <span class="toc-text">How does it scale ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#final-remarks"><span class="toc-number">6.</span> <span class="toc-text">Final remarks</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/"><i class="fa fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&text=Building a fast inference service with falcon and bjoern"><i class="fa fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&is_video=false&description=Building a fast inference service with falcon and bjoern"><i class="fa fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Building a fast inference service with falcon and bjoern&body=Check out this article: https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/"><i class="fa fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&title=Building a fast inference service with falcon and bjoern"><i class="fa fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://alexpnt.github.io/2018/01/06/fast-inference-falcon-bjoern/&name=Building a fast inference service with falcon and bjoern&description="><i class="fa fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
      <ul>
        <li id="toc"><a class="icon" href="#" onclick='$("#toc-footer").toggle();return false;'><i class="fa fa-list fa-lg" aria-hidden="true"></i> TOC</a></li>
        <li id="share"><a class="icon" href="#" onclick='$("#share-footer").toggle();return false;'><i class="fa fa-share-alt fa-lg" aria-hidden="true"></i> Share</a></li>
        <li id="top" style="display:none"><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a></li>
        <li id="menu"><a class="icon" href="#" onclick='$("#nav-footer").toggle();return false;'><i class="fa fa-bars fa-lg" aria-hidden="true"></i> Menu</a></li>
      </ul>
    </div>

  </div>
</div>

    
    <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2020 Alexandre Pinto
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/cv/">CV</a></li>
         
          <li><a href="/blog/">Blog</a></li>
         
          <li><a href="/papers/">Papers</a></li>
        
      </ul>
    </nav>
  </div>
</footer><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
<!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
<link rel="stylesheet" href="/lib/meslo-LG/styles.css">
<link rel="stylesheet" href="/lib/justified-gallery/justifiedGallery.min.css">


<!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/jquery.justifiedGallery.min.js"></script>
<script src="/js/main.js"></script>
<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-43571022-2', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Disqus Comments -->

    <script type="text/javascript">
        var disqus_shortname = 'alexpnt';

        (function(){
            var dsq = document.createElement('script');
            dsq.type = 'text/javascript';
            dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        }());
    </script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

